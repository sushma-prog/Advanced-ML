# ğŸ“˜ Advanced Machine Learning â€” End-to-End Learning Pipeline

> **Focus**: Real-world pipelines Â· Model tuning Â· SHAP & LIME explainability Â· API integration Â· Capstone project deployment

---

## âœ… Week Overview

This week focused on advanced machine learning concepts and practices that go **beyond just training models** â€” diving into tuning, interpretation, automation, and deployment-level workflow design.

---

## ğŸ“… Day-by-Day Breakdown

### ğŸ”¹ **Day 1: Introduction to Gradient Boosting**

- Revisited **bagging vs boosting** principles
- Explored **XGBoost and LightGBM** internals
- Installed and configured libraries
- âœ… Practiced: Trained a basic XGBoost model on the Iris dataset

---

### ğŸ”¹ **Day 2: Cross-Validation & GridSearchCV**

- Understood **cross-validation (CV)** strategies: KFold, StratifiedKFold
- Implemented **GridSearchCV** for hyperparameter tuning
- âœ… Practiced: Tuned `max_depth`, `learning_rate`, and `n_estimators` for XGBoost

---

### ğŸ”¹ **Day 3: LightGBM & RandomizedSearchCV**

- Compared **LightGBM vs XGBoost**
- Trained a LightGBM model using Breast Cancer dataset
- Used **RandomizedSearchCV** for efficient tuning
- âœ… Practiced: Evaluated and compared both models

---

### ğŸ”¹ **Day 4: Model Interpretation with SHAP**

- Learned why interpretability matters in ML
- Used **SHAP** to visualize:
  - Global feature importance (`summary_plot`)
  - Individual prediction reasons (`force_plot`)
  - Feature interactions (`dependence_plot`)
- âœ… Practiced: Visual explanations on Breast Cancer dataset

---

### ğŸ”¹ **Day 5: LIME + API Basics**

- Learned how **LIME** provides local explanation for black-box models
- Compared **SHAP vs LIME**
- Used **LimeTabularExplainer** for per-instance interpretation
- Explored **REST APIs**: What they are and how to call them with Python
- âœ… Practiced: Parsed real-time public API like cat facts using `requests` and `json`

---

### ğŸ”¹ **Day 6: Building a Mini Data Pipeline**

- Designed an ML **data pipeline**: Ingest â†’ Clean â†’ Model â†’ Export
- Used:
  - `pandas` for preprocessing
  - `xgboost` for modeling
  - `joblib` for saving models
  - `SQLite` & CSV for output storage
- âœ… Practiced: Full pipeline built using Titanic dataset

---

### ğŸ”¹ **Day 7: Capstone Project â€” Customer Churn Prediction**

- End-to-end ML project using **Telco Customer Churn** dataset
- Steps performed:
  1. Load and explore dataset
  2. Clean and encode features
  3. Train-test split + XGBoost with GridSearchCV
  4. Interpret model using SHAP & LIME
  5. Save predictions to **CSV** and **SQLite**
- âœ… Outcome: A complete, interpretable, production-ready ML pipeline

---

## ğŸ¯ Tools & Libraries Used

| Category            | Libraries                          |
|---------------------|------------------------------------|
| Modeling            | `xgboost`, `lightgbm`              |
| Tuning              | `sklearn.model_selection`          |
| Interpretation      | `shap`, `lime`                     |
| Data handling       | `pandas`, `numpy`                  |
| Deployment Ready    | `joblib`, `sqlite3`, `csv`         |
| API Integration     | `requests`, `json`                 |

---

## ğŸ“Œ Key Skills Mastered

- Gradient Boosting Algorithms
- Model Hyperparameter Tuning
- SHAP & LIME Interpretation
- Data Pipeline Design
- API Calls with Python
- Model & Output Storage (CSV, DB)

---

## ğŸ“ Project Repositories

> âœ… All completed notebooks and projects from this Week are uploaded here:  
ğŸ”— [Advanced-ML]([https://github.com/sushma-prog/customer-churn-prediction](https://github.com/sushma-prog/Advanced-ML)

---

## ğŸ‘©â€ğŸ’» Author

**Sushma Sandanshiv**  
BTech Data Science | Aspiring Data Analyst  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/sushma-sandanshiv-2740422b7/) â€¢ ğŸ”— [GitHub](https://github.com/sushma-prog)

---

